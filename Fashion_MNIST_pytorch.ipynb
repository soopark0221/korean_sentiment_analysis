{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.datasets.FashionMNIST(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
    "\n",
    "\n",
    "train_f = torchvision.datasets.FashionMNIST('./data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "\n",
    "train_ds = torch.utils.data.DataLoader(train_f)\n",
    "\n",
    "test_f = torchvision.datasets.FashionMNIST('./data/FashionMNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "test_ds = torch.utils.data.DataLoader(test_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([9])\n",
      "torch.float32\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic, labels= next(iter(train_ds))\n",
    "\n",
    "print(pic.shape)\n",
    "print(labels)\n",
    "print(pic.dtype)  #float\n",
    "\n",
    "print(type(pic),type(labels))\n",
    "\n",
    "#print(pic[0][0])\n",
    "plt.imshow(pic[0][0], cmap ='gray') #could use pic.squeeze()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "  # define forward function\n",
    "    def forward(self, t):\n",
    "        # conv 1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # conv 2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # fc1\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # output\n",
    "        t = self.out(t)\n",
    "        # don't need softmax here since we'll use cross-entropy as activation.\n",
    "\n",
    "        return t\n",
    "    \n",
    "Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Step : 2000, Loss : 0.005917766597121954\n",
      "Epoch : 1, Step : 4000, Loss : 0.009331894107162952\n",
      "Epoch : 1, Step : 6000, Loss : 0.020716829225420952\n",
      "Epoch : 1, Step : 8000, Loss : 5.008325099945068\n",
      "Epoch : 1, Step : 10000, Loss : 1.4058995246887207\n",
      "Epoch : 1, Step : 12000, Loss : 0.8048622608184814\n",
      "Epoch : 1, Step : 14000, Loss : 0.48857080936431885\n",
      "Epoch : 1, Step : 16000, Loss : 0.5705184936523438\n",
      "Epoch : 1, Step : 18000, Loss : 0.9870127439498901\n",
      "Epoch : 1, Step : 20000, Loss : 0.3813696801662445\n",
      "Epoch : 1, Step : 22000, Loss : 1.3470558769768104e-05\n",
      "Epoch : 1, Step : 24000, Loss : 0.016960691660642624\n",
      "Epoch : 1, Step : 26000, Loss : 0.1166604608297348\n",
      "Epoch : 1, Step : 28000, Loss : 0.8935072422027588\n",
      "Epoch : 1, Step : 30000, Loss : 0.0002479245886206627\n",
      "Epoch : 1, Step : 32000, Loss : 3.85038583772257e-05\n",
      "Epoch : 1, Step : 34000, Loss : 0.0011636398267000914\n",
      "Epoch : 1, Step : 36000, Loss : 0.9798712134361267\n",
      "Epoch : 1, Step : 38000, Loss : 0.3567570745944977\n",
      "Epoch : 1, Step : 40000, Loss : 1.1217951774597168\n",
      "Epoch : 1, Step : 42000, Loss : 6.937739817658439e-05\n",
      "Epoch : 1, Step : 44000, Loss : 1.1927666664123535\n",
      "Epoch : 1, Step : 46000, Loss : 0.07709584385156631\n",
      "Epoch : 1, Step : 48000, Loss : 0.5687033534049988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-433f08455892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# computes dloss/dx for every parameter.accumulated into x.grad for every parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Performs a single optimization step. updates the value of x using the gradient x.grad.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "epochs= 3\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = Network()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_step = len(train_ds)\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    print(type(param), param.size())\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    loss_total = 0\n",
    "    for i, (images, labels) in enumerate(train_ds):\n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor s to zero.\n",
    "        \n",
    "        #forward+backward+optimize\n",
    "        out = model(images)\n",
    "        loss = criterion(out,labels)\n",
    "        temp = loss.item()\n",
    "        loss.backward() # computes dloss/dx for every parameter.accumulated into x.grad for every parameter\n",
    "        optimizer.step()  # Performs a single optimization step. updates the value of x using the gradient x.grad.\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (i+1)%2000 == 0:\n",
    "            print('Epoch : {}, Step : {}, Loss : {}'.format(epoch+1, i+1, temp))\n",
    "            loss_total = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch: 1, loss : 2.3012523651123047\n",
      "epoch: 1, batch: 2, loss : 2.30334734916687\n",
      "epoch: 1, batch: 3, loss : 2.296525478363037\n",
      "epoch: 1, batch: 4, loss : 2.2867870330810547\n",
      "epoch: 1, batch: 5, loss : 2.2720656394958496\n",
      "epoch: 1, batch: 6, loss : 2.2601962089538574\n",
      "epoch: 1, batch: 7, loss : 2.2376391887664795\n",
      "epoch: 1, batch: 8, loss : 2.2119693756103516\n",
      "epoch: 1, batch: 9, loss : 2.18949818611145\n",
      "epoch: 1, batch: 10, loss : 2.138474941253662\n",
      "epoch: 1, batch: 11, loss : 2.090165376663208\n",
      "epoch: 1, batch: 12, loss : 2.0421152114868164\n",
      "epoch: 1, batch: 13, loss : 1.9753972291946411\n",
      "epoch: 1, batch: 14, loss : 1.8907575607299805\n",
      "epoch: 1, batch: 15, loss : 1.8450435400009155\n",
      "epoch: 1, batch: 16, loss : 1.764786958694458\n",
      "epoch: 1, batch: 17, loss : 1.6911084651947021\n",
      "epoch: 1, batch: 18, loss : 1.627849817276001\n",
      "epoch: 1, batch: 19, loss : 1.5503262281417847\n",
      "epoch: 1, batch: 20, loss : 1.4867289066314697\n",
      "epoch: 1, batch: 21, loss : 1.4189327955245972\n",
      "epoch: 1, batch: 22, loss : 1.3543788194656372\n",
      "epoch: 1, batch: 23, loss : 1.28950035572052\n",
      "epoch: 1, batch: 24, loss : 1.224682092666626\n",
      "epoch: 1, batch: 25, loss : 1.191890001296997\n",
      "epoch: 1, batch: 26, loss : 1.1107245683670044\n",
      "epoch: 1, batch: 27, loss : 1.1367586851119995\n",
      "epoch: 1, batch: 28, loss : 1.1013845205307007\n",
      "epoch: 1, batch: 29, loss : 1.047252893447876\n",
      "epoch: 1, batch: 30, loss : 1.0586682558059692\n",
      "epoch: 1, batch: 31, loss : 0.9770389199256897\n",
      "epoch: 1, batch: 32, loss : 0.9921092987060547\n",
      "epoch: 1, batch: 33, loss : 0.9803888201713562\n",
      "epoch: 1, batch: 34, loss : 0.9815071821212769\n",
      "epoch: 1, batch: 35, loss : 0.9845303297042847\n",
      "epoch: 1, batch: 36, loss : 0.887897253036499\n",
      "epoch: 1, batch: 37, loss : 0.9527074098587036\n",
      "epoch: 1, batch: 38, loss : 0.8734502792358398\n",
      "epoch: 1, batch: 39, loss : 0.8846591711044312\n",
      "epoch: 1, batch: 40, loss : 0.89654141664505\n",
      "epoch: 1, batch: 41, loss : 0.8679407238960266\n",
      "epoch: 1, batch: 42, loss : 0.884750247001648\n",
      "epoch: 1, batch: 43, loss : 0.8615381717681885\n",
      "epoch: 1, batch: 44, loss : 0.8459914922714233\n",
      "epoch: 1, batch: 45, loss : 0.8683881163597107\n",
      "epoch: 1, batch: 46, loss : 0.8863638639450073\n",
      "epoch: 1, batch: 47, loss : 0.8419492840766907\n",
      "epoch: 1, batch: 48, loss : 0.8282562494277954\n",
      "epoch: 1, batch: 49, loss : 0.7608081698417664\n",
      "epoch: 1, batch: 50, loss : 0.8072820901870728\n",
      "epoch: 1, batch: 51, loss : 0.804178774356842\n",
      "epoch: 1, batch: 52, loss : 0.8016406297683716\n",
      "epoch: 1, batch: 53, loss : 0.8253201246261597\n",
      "epoch: 1, batch: 54, loss : 0.8319858908653259\n",
      "epoch: 1, batch: 55, loss : 0.82834792137146\n",
      "epoch: 1, batch: 56, loss : 0.7483839392662048\n",
      "epoch: 1, batch: 57, loss : 0.7947958111763\n",
      "epoch: 1, batch: 58, loss : 0.7396839261054993\n",
      "epoch: 1, batch: 59, loss : 0.776939868927002\n",
      "epoch: 1, batch: 60, loss : 0.7636734247207642\n",
      "epoch: 2, batch: 1, loss : 0.742110013961792\n",
      "epoch: 2, batch: 2, loss : 0.7680021524429321\n",
      "epoch: 2, batch: 3, loss : 0.8077716827392578\n",
      "epoch: 2, batch: 4, loss : 0.7509384155273438\n",
      "epoch: 2, batch: 5, loss : 0.6761026978492737\n",
      "epoch: 2, batch: 6, loss : 0.7632521986961365\n",
      "epoch: 2, batch: 7, loss : 0.7276062965393066\n",
      "epoch: 2, batch: 8, loss : 0.7672061920166016\n",
      "epoch: 2, batch: 9, loss : 0.7451236248016357\n",
      "epoch: 2, batch: 10, loss : 0.7279061675071716\n",
      "epoch: 2, batch: 11, loss : 0.6754283308982849\n",
      "epoch: 2, batch: 12, loss : 0.7678818702697754\n",
      "epoch: 2, batch: 13, loss : 0.7013313174247742\n",
      "epoch: 2, batch: 14, loss : 0.7298027873039246\n",
      "epoch: 2, batch: 15, loss : 0.6975370645523071\n",
      "epoch: 2, batch: 16, loss : 0.7219564914703369\n",
      "epoch: 2, batch: 17, loss : 0.7164642810821533\n",
      "epoch: 2, batch: 18, loss : 0.7341955900192261\n",
      "epoch: 2, batch: 19, loss : 0.7218349575996399\n",
      "epoch: 2, batch: 20, loss : 0.7325406670570374\n",
      "epoch: 2, batch: 21, loss : 0.7108999490737915\n",
      "epoch: 2, batch: 22, loss : 0.7056577801704407\n",
      "epoch: 2, batch: 23, loss : 0.7186588048934937\n",
      "epoch: 2, batch: 24, loss : 0.6600571274757385\n",
      "epoch: 2, batch: 25, loss : 0.7279624342918396\n",
      "epoch: 2, batch: 26, loss : 0.6445034742355347\n",
      "epoch: 2, batch: 27, loss : 0.6650616526603699\n",
      "epoch: 2, batch: 28, loss : 0.6951246857643127\n",
      "epoch: 2, batch: 29, loss : 0.71333909034729\n",
      "epoch: 2, batch: 30, loss : 0.6839663982391357\n",
      "epoch: 2, batch: 31, loss : 0.6661329865455627\n",
      "epoch: 2, batch: 32, loss : 0.6371586322784424\n",
      "epoch: 2, batch: 33, loss : 0.6457911133766174\n",
      "epoch: 2, batch: 34, loss : 0.6702228784561157\n",
      "epoch: 2, batch: 35, loss : 0.7009605765342712\n",
      "epoch: 2, batch: 36, loss : 0.645930826663971\n",
      "epoch: 2, batch: 37, loss : 0.7025365829467773\n",
      "epoch: 2, batch: 38, loss : 0.6404826045036316\n",
      "epoch: 2, batch: 39, loss : 0.648210883140564\n",
      "epoch: 2, batch: 40, loss : 0.6472787261009216\n",
      "epoch: 2, batch: 41, loss : 0.6498516201972961\n",
      "epoch: 2, batch: 42, loss : 0.6498152017593384\n",
      "epoch: 2, batch: 43, loss : 0.6467044353485107\n",
      "epoch: 2, batch: 44, loss : 0.626237690448761\n",
      "epoch: 2, batch: 45, loss : 0.6522600650787354\n",
      "epoch: 2, batch: 46, loss : 0.7046973705291748\n",
      "epoch: 2, batch: 47, loss : 0.6424027681350708\n",
      "epoch: 2, batch: 48, loss : 0.6348840594291687\n",
      "epoch: 2, batch: 49, loss : 0.5972154140472412\n",
      "epoch: 2, batch: 50, loss : 0.6282501816749573\n",
      "epoch: 2, batch: 51, loss : 0.6301977038383484\n",
      "epoch: 2, batch: 52, loss : 0.641178548336029\n",
      "epoch: 2, batch: 53, loss : 0.6810566186904907\n",
      "epoch: 2, batch: 54, loss : 0.7080108523368835\n",
      "epoch: 2, batch: 55, loss : 0.6677505373954773\n",
      "epoch: 2, batch: 56, loss : 0.583496630191803\n",
      "epoch: 2, batch: 57, loss : 0.6450945138931274\n",
      "epoch: 2, batch: 58, loss : 0.5765466690063477\n",
      "epoch: 2, batch: 59, loss : 0.6194276809692383\n",
      "epoch: 2, batch: 60, loss : 0.6418070793151855\n",
      "epoch: 3, batch: 1, loss : 0.583736777305603\n",
      "epoch: 3, batch: 2, loss : 0.6468523740768433\n",
      "epoch: 3, batch: 3, loss : 0.6523618698120117\n",
      "epoch: 3, batch: 4, loss : 0.6499496698379517\n",
      "epoch: 3, batch: 5, loss : 0.5545142292976379\n",
      "epoch: 3, batch: 6, loss : 0.6393263339996338\n",
      "epoch: 3, batch: 7, loss : 0.6086763143539429\n",
      "epoch: 3, batch: 8, loss : 0.6545149683952332\n",
      "epoch: 3, batch: 9, loss : 0.6374838948249817\n",
      "epoch: 3, batch: 10, loss : 0.6127002835273743\n",
      "epoch: 3, batch: 11, loss : 0.5893831849098206\n",
      "epoch: 3, batch: 12, loss : 0.6469444632530212\n",
      "epoch: 3, batch: 13, loss : 0.584394633769989\n",
      "epoch: 3, batch: 14, loss : 0.6385631561279297\n",
      "epoch: 3, batch: 15, loss : 0.6046422719955444\n",
      "epoch: 3, batch: 16, loss : 0.6125646829605103\n",
      "epoch: 3, batch: 17, loss : 0.6426579356193542\n",
      "epoch: 3, batch: 18, loss : 0.6394526362419128\n",
      "epoch: 3, batch: 19, loss : 0.6262713670730591\n",
      "epoch: 3, batch: 20, loss : 0.6429665088653564\n",
      "epoch: 3, batch: 21, loss : 0.6267033815383911\n",
      "epoch: 3, batch: 22, loss : 0.5902600288391113\n",
      "epoch: 3, batch: 23, loss : 0.6200547814369202\n",
      "epoch: 3, batch: 24, loss : 0.5831683874130249\n",
      "epoch: 3, batch: 25, loss : 0.6265146732330322\n",
      "epoch: 3, batch: 26, loss : 0.5461509823799133\n",
      "epoch: 3, batch: 27, loss : 0.5806508660316467\n",
      "epoch: 3, batch: 28, loss : 0.5947767496109009\n",
      "epoch: 3, batch: 29, loss : 0.6185058355331421\n",
      "epoch: 3, batch: 30, loss : 0.6162450313568115\n",
      "epoch: 3, batch: 31, loss : 0.5850698947906494\n",
      "epoch: 3, batch: 32, loss : 0.5677624344825745\n",
      "epoch: 3, batch: 33, loss : 0.5703441500663757\n",
      "epoch: 3, batch: 34, loss : 0.5885950326919556\n",
      "epoch: 3, batch: 35, loss : 0.6049035787582397\n",
      "epoch: 3, batch: 36, loss : 0.5882333517074585\n",
      "epoch: 3, batch: 37, loss : 0.6329207420349121\n",
      "epoch: 3, batch: 38, loss : 0.5690114498138428\n",
      "epoch: 3, batch: 39, loss : 0.5966032147407532\n",
      "epoch: 3, batch: 40, loss : 0.5732232928276062\n",
      "epoch: 3, batch: 41, loss : 0.5713464021682739\n",
      "epoch: 3, batch: 42, loss : 0.5732479691505432\n",
      "epoch: 3, batch: 43, loss : 0.570942223072052\n",
      "epoch: 3, batch: 44, loss : 0.56622713804245\n",
      "epoch: 3, batch: 45, loss : 0.5762954354286194\n",
      "epoch: 3, batch: 46, loss : 0.6447234749794006\n",
      "epoch: 3, batch: 47, loss : 0.5664644241333008\n",
      "epoch: 3, batch: 48, loss : 0.5661746859550476\n",
      "epoch: 3, batch: 49, loss : 0.5433127284049988\n",
      "epoch: 3, batch: 50, loss : 0.5752753615379333\n",
      "epoch: 3, batch: 51, loss : 0.5670633912086487\n",
      "epoch: 3, batch: 52, loss : 0.570868968963623\n",
      "epoch: 3, batch: 53, loss : 0.6271782517433167\n",
      "epoch: 3, batch: 54, loss : 0.6435133218765259\n",
      "epoch: 3, batch: 55, loss : 0.6180716156959534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, batch: 56, loss : 0.5242824554443359\n",
      "epoch: 3, batch: 57, loss : 0.5853066444396973\n",
      "epoch: 3, batch: 58, loss : 0.5394557118415833\n",
      "epoch: 3, batch: 59, loss : 0.5514712929725647\n",
      "epoch: 3, batch: 60, loss : 0.5965719223022461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs= 3\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = Network()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_b = torch.utils.data.DataLoader(train_f, batch_size = 1000)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_total = 0\n",
    "    batch_n = 0\n",
    "    for batch in train_b:\n",
    "        model.train()\n",
    "        images, labels = batch\n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor s to zero.\n",
    "        \n",
    "        #forward+backward+optimize\n",
    "        out = model(images)\n",
    "        loss = criterion(out,labels)\n",
    "        loss.backward() # computes dloss/dx for every parameter.accumulated into x.grad for every parameter\n",
    "        optimizer.step()  # Performs a single optimization step. updates the value of x using the gradient x.grad.\n",
    "        \n",
    "        loss_total += loss.item()\n",
    "        batch_n+=1\n",
    "        \n",
    "        \n",
    "        print('epoch: {}, batch: {}, loss : {}'.format(epoch+1, batch_n,loss.item()))\n",
    "        loss_total = 0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on the test images : 77.63%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_ds:\n",
    "        images, labels = data\n",
    "        out = model(images)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of network on the test images : {}%'.format(correct/total*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
